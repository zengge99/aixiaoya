import onnxruntime as ort
import pickle
import re
import sys
import os
import argparse
from flask import Flask, request, jsonify

# --- å…¨å±€é…ç½® ---
MAX_LEN = 300
THRESHOLD = 0.35
VOCAB_PATH = "vocab.pkl"
ONNX_MODEL_PATH = "movie_extractor.onnx"
DEBUG_MODE = os.path.exists("dbg")

# --- å¿…éœ€å·¥å…·ç±» TextUtils ---
class TextUtils:
    CN_NUMS = ["é›¶", "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]

    @staticmethod
    def cn_to_arabic(cn_str):
        """å°†ä¸­æ–‡æ•°å­—ï¼ˆä¸€åˆ°ä¹åä¹ï¼‰è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼çš„é˜¿æ‹‰ä¼¯æ•°å­—"""
        cn_num_map = {'é›¶':0, 'ä¸€':1, 'äºŒ':2, 'ä¸‰':3, 'å››':4, 'äº”':5, 'å…­':6, 'ä¸ƒ':7, 'å…«':8, 'ä¹':9}
        
        # å¦‚æœæœ¬èº«å°±æ˜¯é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if cn_str.isdigit():
            return cn_str
        
        # å¤„ç†é€»è¾‘
        if cn_str == "å":
            return "10"
        
        res = 0
        if "å" in cn_str:
            parts = cn_str.split("å")
            # å¤„ç† "äºŒå..." æˆ– "å..."
            # å¦‚æœ "å" åœ¨å¼€å¤´ï¼ˆå¦‚åä¸€ï¼‰ï¼Œå‰éƒ¨åˆ†ä¸ºç©º
            prefix = parts[0]
            suffix = parts[1]
            
            if prefix: # äºŒå...
                res += cn_num_map[prefix] * 10
            else: # å...
                res += 10
                
            if suffix: # ...åä¸€
                res += cn_num_map[suffix]
        else:
            # ä»…æœ‰ä¸ªä½æ•°
            res = cn_num_map.get(cn_str, cn_str)
            
        return str(res)

    @staticmethod
    def simplify_season_name(text):
        """
        æ ¸å¿ƒè½¬æ¢å‡½æ•°
        ä¾‹å¦‚: 'åŠŸå¤«ç†ŠçŒ« ç¬¬åä¸€å­£' -> 'åŠŸå¤«ç†ŠçŒ«11'
        """
        # æ­£åˆ™åŒ¹é…ï¼šåŒ¹é…â€œç¬¬â€åé¢è·Ÿç€çš„ä¸€ä¸²ä¸­æ–‡æ•°å­—æˆ–é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œç›´åˆ°â€œå­£â€
        pattern = r'\s*ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)å­£'
        
        def replace_func(match):
            cn_val = match.group(1)
            return TextUtils.cn_to_arabic(cn_val)

        # ä½¿ç”¨ re.sub è¿›è¡Œæ›¿æ¢
        result = re.sub(pattern, replace_func, text)
        return result.strip()

    @staticmethod
    def number2text(text):
        if not text: return text
        text = text.lstrip('0')
        if not text: return "é›¶" 

        try:
            num = int(text)
        except ValueError:
            return text

        if num <= 10:
            return TextUtils.CN_NUMS[num]
        elif num < 20:
            return "å" + TextUtils.CN_NUMS[num % 10]
        elif num % 10 == 0:
            return TextUtils.CN_NUMS[num // 10] + "å"
        else:
            return TextUtils.CN_NUMS[num // 10] + "å" + TextUtils.CN_NUMS[num % 10]

    @staticmethod
    def fix_name_internal(path, ai_result):
        if ai_result and all(ord(c) < 128 for c in ai_result):
            return ai_result
        processed_result = ai_result

        cn_season_pattern = r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+å­£'
        cn_match = re.search(cn_season_pattern, path)
        if cn_match:
            suffix = cn_match.group(0)
            if suffix not in processed_result:
                return f"{processed_result} {suffix}".strip()
            return processed_result

        replaced_flag = False 

        def replace_func(match):
            nonlocal replaced_flag
            replaced_flag = True
            num = match.group(1)
            cn_num = TextUtils.number2text(num)
            return f" ç¬¬{cn_num}å­£ " 

        for pattern in replace_patterns:
            if re.search(pattern, processed_result, re.IGNORECASE):
                processed_result = re.sub(pattern, replace_func, processed_result, flags=re.IGNORECASE)
        
        processed_result = re.sub(r'\s+', ' ', processed_result).strip()

        if replaced_flag:
            return processed_result

        path_search_patterns = [
            r'Season\s*(\d{1,2})',
            r'SE(\d{1,2})',
            r'ç¬¬(\d{1,2})å­£',
            r'(?<![A-Za-z])S(\d{1,2})'
        ]

        for pattern in path_search_patterns:
            match = re.search(pattern, path, re.IGNORECASE)
            if match:
                num = match.group(1)
                cn_num = TextUtils.number2text(num)
                suffix = f"ç¬¬{cn_num}å­£"
                if suffix not in processed_result:
                    return f"{processed_result} {suffix}"
                break 
        
        return processed_result

    @staticmethod
    def fix_name(path, ai_result):
        result = TextUtils.fix_name_internal(path, ai_result).replace("ç¬¬ä¸€å­£", "", 1).strip()
        # tmdbä¸å¤ªè®¤â€œåŠŸå¤«ç†ŠçŒ« ç¬¬ä¸‰å­£â€è¿™ç§ï¼Œè¦è½¬æ¢æˆâ€œåŠŸå¤«ç†ŠçŒ«3â€
        return TextUtils.simplify_season_name(result)

def get_resource_path(relative_path):
    if os.path.exists(relative_path):
        return relative_path
    if hasattr(sys, '_MEIPASS'):
        bundle_path = os.path.join(sys._MEIPASS, relative_path)
        if os.path.exists(bundle_path):
            return bundle_path
    exe_dir_path = os.path.join(os.path.dirname(sys.executable), relative_path)
    if os.path.exists(exe_dir_path):
        return exe_dir_path
    return relative_path

# --- ONNX åˆå§‹åŒ– ---
def init_onnx_session():
    actual_onnx_path = get_resource_path(ONNX_MODEL_PATH)
    actual_vocab_path = get_resource_path(VOCAB_PATH)

    if not os.path.exists(actual_onnx_path) or not os.path.exists(actual_vocab_path):
        print(f"âŒ ç¼ºå¤±æ–‡ä»¶ï¼šéœ€ {ONNX_MODEL_PATH} å’Œ {VOCAB_PATH} åœ¨åŒç›®å½•")
        return None, None
    
    with open(actual_vocab_path, 'rb') as f:
        char_to_idx = pickle.load(f)
    
    sess = ort.InferenceSession(
        actual_onnx_path,
        providers=["CPUExecutionProvider"],
        sess_options=ort.SessionOptions()
    )
    return sess, char_to_idx

# --- æ ¸å¿ƒæ¨ç†é€»è¾‘æå– ---
def do_inference(path, sess, char_to_idx):
    if '#' in path:
        return "" # åŸé€»è¾‘ä¸­ç¢°åˆ°#å·ç›´æ¥è¿”å›ç©ºæˆ–æ‰“å°åŸè·¯å¾„
    
    input_ids = [char_to_idx.get(c.lower(), 1) for c in path[:MAX_LEN]]
    padded = input_ids + [0] * (MAX_LEN - len(input_ids))
    padded = [padded]

    outputs = sess.run(["probs"], {"input_ids": padded})
    probs = outputs[0][0][:len(path)]
    if DEBUG_MODE:
        print(f"\n{'='*65}")
        print(f"{'ç´¢å¼•':<4} | {'å­—ç¬¦':<4} | {'åˆ†å€¼':<15} | çŠ¶æ€")
        print("-" * 65)
        for i, p in enumerate(probs):
            status = "âœ… [é€‰ä¸­]" if p > THRESHOLD else "   [æ’é™¤]"
            print(f"{i:<4} | {path[i]:<4} | {p:.10f} | {status}")
        print(f"{'='*65}\n")
    selected_mask = [False] * len(probs)
    for i, p in enumerate(probs):
        if p > THRESHOLD:
            selected_mask[i] = True
            
    gap_limit = 2 
    for i in range(len(probs)):
        if selected_mask[i]:
            for j in range(i + 1, min(i + gap_limit + 2, len(probs))):
                if selected_mask[j]:
                    for k in range(i + 1, j):
                        if path[k] not in ['/', '\\']:
                            selected_mask[k] = True
                    break

    res_list = [path[i] for i, is_sel in enumerate(selected_mask) if is_sel]
    raw_result = "".join(res_list)
    clean_result = raw_result.replace('.', ' ').replace('_', ' ')
    clean_result = re.sub(r'\s+', ' ', clean_result)
    clean_result = clean_result.strip("/()# â€œâ€.-")

    if clean_result:
        escaped_clean = re.escape(clean_result)
        verify_pattern = escaped_clean.replace(r'\ ', r'[._\s\-\(\)\[\]]*')
        if not re.search(verify_pattern, path, re.IGNORECASE):
            clean_result = ""

    if clean_result:
        clean_result = TextUtils.fix_name(path, clean_result)
    
    return clean_result

# --- é¢„æµ‹åŠ¨ä½œå°è£… ---
def predict_single_path(path, sess, char_to_idx):
    res = do_inference(path, sess, char_to_idx)
    if res:
        print(f"{path}#{res}")
    else:
        print(f"{path}")

def run_batch_predict(file_path, sess, char_to_idx):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f.readlines() if line.strip()]
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    for line in lines:
        predict_single_path(line, sess, char_to_idx)

# --- HTTP æœåŠ¡æ¨¡å¼ ---
def start_server(port):
    app = Flask(__name__)

    @app.route('/')
    def api_extract():
        q = request.args.get('q', '')
        if not q:
            return jsonify({"error": "missing parameter q"}), 400
        sess, char_to_idx = init_onnx_session()
        result = do_inference(q, sess, char_to_idx)
        print(f"{result}")
        return result  # ç›´æ¥è¿”å›æå–å‡ºçš„å­—ç¬¦ä¸²

    print(f"ğŸš€ HTTP æœåŠ¡å·²å¯åŠ¨: http://0.0.0.0:{port}")
    print(f"ğŸ“Œ ä½¿ç”¨ç¤ºä¾‹: http://127.0.0.1:{port}/?q=ä½ çš„å½±ç‰‡è·¯å¾„")
    app.run(host='0.0.0.0', port=port, debug=False)

# --- å…¥å£æ§åˆ¶ ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç”µå½±åç§°æå–å·¥å…·")
    parser.add_argument("input", nargs="?", help="å½±ç‰‡è·¯å¾„å­—ç¬¦ä¸² æˆ– è·¯å¾„åˆ—è¡¨æ–‡ä»¶(.txt)")
    parser.add_argument("--srv", type=int, help="å¯åŠ¨ HTTP æœåŠ¡æ¨¡å¼ï¼ŒæŒ‡å®šç«¯å£å·")

    args = parser.parse_args()

    # åˆå§‹åŒ–æ¨¡å‹
    sess, char_to_idx = init_onnx_session()
    if not sess:
        sys.exit(1)

    # ä¼˜å…ˆåˆ¤æ–­æ˜¯å¦å¯åŠ¨æœåŠ¡
    if args.srv:
        start_server(args.srv)
    
    # å…¶æ¬¡åˆ¤æ–­æ˜¯å¦æœ‰è¾“å…¥è·¯å¾„è¿›è¡Œå•æ¡æˆ–æ‰¹é‡é¢„æµ‹
    elif args.input:
        if os.path.exists(args.input) and os.path.isfile(args.input):
            run_batch_predict(args.input, sess, char_to_idx)
        else:
            predict_single_path(args.input, sess, char_to_idx)
    else:
        parser.print_help()